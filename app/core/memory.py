import sqlite3
import json
import os
import logging
from datetime import datetime
from typing import List, Dict, Optional
from datetime import timedelta
import re
import statistics
from app.config import BASE_APP_DIR
from app.core.text_utils import SimHash, FeatureExtractor


class MemoryManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –ø–∞–º—è—Ç–∏ —Å RAG (Retrieval-Augmented Generation)
    - SQLite –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    - Keyword search –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
    """

    def __init__(self, db_path=None):
        if db_path is None:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤–Ω—É—Ç—Ä–∏ BASE_APP_DIR
            self.db_path = os.path.join(BASE_APP_DIR, "data", "memory.db")
        else:
            self.db_path = db_path

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç (–≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –ø–∞–ø–∫–∞ 'data' —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–∞)
        db_dir = os.path.dirname(self.db_path)
        if db_dir and not os.path.exists(db_dir):
            os.makedirs(db_dir, exist_ok=True)

        self._init_db()
        self._stats_cache = {}

    def _get_conn(self):
        return sqlite3.connect(self.db_path)

    # ==================== SQLite ====================

    def _init_db(self):
        with self._get_conn() as conn:
            cursor = conn.cursor()
            # –¢–∞–±–ª–∏—Ü–∞ —Ç–æ–≤–∞—Ä–æ–≤
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS items (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    avito_id TEXT UNIQUE,
                    title TEXT,
                    price INTEGER,
                    description TEXT,
                    url TEXT,
                    seller TEXT,
                    address TEXT,
                    published_date TEXT,
                    added_at TEXT,  -- –ò–°–ü–†–ê–í–õ–ï–ù–û: –±—ã–ª–æ parsed_date, —Å—Ç–∞–ª–æ added_at
                    
                    -- AI –ø–æ–ª—è
                    verdict TEXT,
                    reason TEXT,
                    market_position TEXT,
                    defects BOOLEAN,
                    
                    -- –ú–µ—Ç–∞
                    category TEXT,
                    tags TEXT
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–ö—ç—à RAG)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS statistics (
                    product_key TEXT PRIMARY KEY,
                    avg_price INTEGER,
                    median_price INTEGER,
                    min_price INTEGER,
                    max_price INTEGER,
                    sample_count INTEGER,
                    trend TEXT,
                    trend_percent REAL,
                    last_updated TEXT
                )
            """)

            # –¢–∞–±–ª–∏—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ç—Ä–µ–Ω–¥–æ–≤
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS trend_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    product_key TEXT,
                    date TEXT,
                    avg_price INTEGER,
                    sample_count INTEGER
                )
            """)
            
            # –¢–∞–±–ª–∏—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS chat_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    role TEXT,
                    content TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            """)
            conn.commit()

    # ==================== –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–æ–≤ ====================

    def add_item(self, item: dict):
        with self._get_conn() as conn:
            cursor = conn.cursor()
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                cursor.execute("SELECT id FROM items WHERE avito_id = ?", (str(item.get('id')),))
                if cursor.fetchone():
                    return False # –£–∂–µ –µ—Å—Ç—å

                # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º added_at –≤–º–µ—Å—Ç–æ parsed_date
                cursor.execute("""
                    INSERT INTO items (
                        avito_id, title, price, description, url, seller, address, 
                        published_date, added_at, verdict, reason, market_position, defects
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    str(item.get('id')),
                    item.get('title'),
                    item.get('price'),
                    item.get('description'),
                    item.get('link'),
                    item.get('seller'),
                    item.get('address'),
                    item.get('date'),
                    datetime.now().isoformat(), # –≠—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–π–¥–µ—Ç –≤ added_at
                    # AI Results
                    item.get('verdict'),
                    item.get('reason'),
                    item.get('market_position'),
                    item.get('defects')
                ))
                conn.commit()
                return True
            except Exception as e:
                print(f"DB Error: {e}")
                return False

    # ==================== –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ ====================

    def find_similar_items(self, query_text: str, limit: int = 20) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (SQL LIKE)

        Args:
            query_text: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
            limit: –ú–∞–∫—Å–∏–º—É–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ SQLite
        """
        return self._find_similar_by_keywords(query_text, limit)

    def _find_similar_by_keywords(self, title: str, limit: int = 20) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (SQL LIKE)"""
        try:
            keywords = self._extract_keywords(title)
            if not keywords:
                return []

            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            c = conn.cursor()

            # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å (–∑–∞—â–∏—Ç–∞ –æ—Ç SQL injection)
            query_parts = []
            params = []
            for kw in keywords:
                query_parts.append("title LIKE ?")
                params.append(f"%{kw}%")

            query = " OR ".join(query_parts)
            params.append(limit)

            c.execute(f"""
                SELECT * FROM items
                WHERE ({query})
                ORDER BY added_at DESC
                LIMIT ?
            """, params)

            rows = [dict(row) for row in c.fetchall()]
            conn.close()

            print(f"[Memory] üîç Keyword search: {len(rows)} results for '{title[:30]}'")
            return rows

        except Exception as e:
            print(f"[Memory] Keyword search error: {e}")
            return []

    def _extract_keywords(self, title: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"""
        # –£–±–∏—Ä–∞–µ–º —à—É–º
        noise_pattern = r'\b(–Ω–æ–≤—ã–π|–±/—É|—Å—Ä–æ—á–Ω–æ|–æ–±–º–µ–Ω|—Ç–æ—Ä–≥|–ø—Ä–æ–¥–∞–º|–∫—É–ø–ª—é|—Ü–µ–Ω–∞|—Ä—É–±|—Ä—É–±–ª–µ–π)\b'
        clean_title = re.sub(noise_pattern, '', title.lower(), flags=re.IGNORECASE)

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞ –∏ –±–µ—Ä–µ–º –∑–Ω–∞—á–∏–º—ã–µ (–¥–ª–∏–Ω–∞ > 2)
        words = clean_title.split()
        keywords = [w for w in words if len(w) > 2][:5]  # –ü–µ—Ä–≤—ã–µ 5 –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤
        return keywords

    # ==================== RAG –ö–æ–Ω—Ç–µ–∫—Å—Ç ====================

    def get_rag_context_for_item(self, title: str, days_back: int = 30) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å RAG-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è —Ç–æ–≤–∞—Ä–∞ (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ—Ö–æ–∂–∏–º)
        Args:
            title: –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            days_back: –°–∫–æ–ª—å–∫–æ –¥–Ω–µ–π –Ω–∞–∑–∞–¥ —É—á–∏—Ç—ã–≤–∞—Ç—å
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å avg_price, median_price, trend, trend_percent, sample_count –∏–ª–∏ None
        """
        
        # --- NEW: –°—Ä–∞–∑—É –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏—á–∏ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ ---
        # –≠—Ç–æ –Ω—É–∂–Ω–æ –¥–ª—è product_key –∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        query_features = FeatureExtractor.extract_features(title)
        query_hash = SimHash.get_hash(title)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ _generate_product_key, —á—Ç–æ–±—ã –Ω–µ –ª–æ–º–∞—Ç—å —Å—Ç–∞—Ä—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        # (–∏–ª–∏ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–µ–ª–∞—Ç—å –µ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ query_features, –Ω–æ –ø–æ–∫–∞ –æ—Å—Ç–∞–≤–∏–º –∫–∞–∫ –µ—Å—Ç—å)
        product_key = self._generate_product_key(title) 
        cached_stats = self._get_cached_stats(product_key)

        if cached_stats:
            print(f"[Memory] üìä Using cached stats for '{title[:30]}'")
            return cached_stats

        # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã
        # --- CHANGE: –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º limit, —Ç–∞–∫ –∫–∞–∫ –±—É–¥–µ–º –∂–µ—Å—Ç–∫–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å ---
        similar_items = self.find_similar_items(title, limit=150) 
        if not similar_items:
            return None

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π)
        cutoff_date = (datetime.now() - timedelta(days=days_back)).strftime("%Y-%m-%d")
        
        # --- NEW: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è ---
        filtered_items = []
        for item in similar_items:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç—ã
            if item.get('added_at', '') < cutoff_date:
                continue

            # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–Ω—ã (–∑–∞—â–∏—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞)
            if not item.get('price') or item['price'] < 100:
                continue

            # 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º (Features)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏ —Ç–æ–≤–∞—Ä–∞ (–∏–∑ –ë–î –∏–ª–∏ –Ω–∞ –ª–µ—Ç—É)
            item_features = {}
            if item.get('features'):
                try:
                    item_features = json.loads(item['features'])
                except: 
                    # –§–æ–ª–±—ç–∫, –µ—Å–ª–∏ JSON –±–∏—Ç—ã–π
                    item_features = FeatureExtractor.extract_features(item.get('title', ''))
            else:
                # –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä —Å—Ç–∞—Ä—ã–π –∏ –ø–æ–ª—è features –µ—â–µ –Ω–µ—Ç
                item_features = FeatureExtractor.extract_features(item.get('title', ''))

            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            mismatch = False
            # –°–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–π, –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º–æ
            critical_keys = ['storage', 'ram', 'model_suffix'] 
            
            for key in critical_keys:
                if key in query_features and key in item_features:
                    # –ï—Å–ª–∏ —É –Ω–∞—Å iPhone 13 Pro, –∞ –Ω–∞—à–ª–∏ iPhone 13 (–±–µ–∑ Pro) -> mismatch
                    # –ù–æ —Ç—É—Ç –Ω—é–∞–Ω—Å: –µ—Å–ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ "Pro", –∞ –≤ —Ç–æ–≤–∞—Ä–µ –Ω–µ—Ç —Å—É—Ñ—Ñ–∏–∫—Å–∞ - —ç—Ç–æ mismatch.
                    # –ê –µ—Å–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç? –û–±—ã—á–Ω–æ —Ç–æ–∂–µ. –ü–æ—ç—Ç–æ–º—É —Å—Ç—Ä–æ–≥–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ.
                    if query_features[key] != item_features[key]:
                        mismatch = True
                        break
            
            if mismatch:
                continue

            # 4. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ SimHash (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å)
            item_hash = item.get('simhash')
            if not item_hash:
                # –ï—Å–ª–∏ —Ö–µ—à–∞ –Ω–µ—Ç –≤ –ë–î, —Å—á–∏—Ç–∞–µ–º –Ω–∞ –ª–µ—Ç—É
                item_hash = SimHash.get_hash(item.get('title', ''))
            
            dist = SimHash.distance(query_hash, item_hash)
            
            # –ü–æ—Ä–æ–≥ 25 –±–∏—Ç –ø–æ–¥–æ–±—Ä–∞–Ω —ç–º–ø–∏—Ä–∏—á–µ—Å–∫–∏ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤.
            # –ú–æ–∂–Ω–æ —É–∂–µ—Å—Ç–æ—á–∏—Ç—å –¥–æ 15-20 –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
            if dist > 25:
                continue

            filtered_items.append(item)

        # --- END NEW ---

        if len(filtered_items) < 2:
            return None

        # –°–æ–±–∏—Ä–∞–µ–º —Ü–µ–Ω—ã
        prices = [item['price'] for item in filtered_items] # –ø—Ä–æ–≤–µ—Ä–∫–∞ if item.get('price') —É–∂–µ –±—ã–ª–∞ –≤—ã—à–µ
        
        # –†–∞—Å—á–µ—Ç —Ç—Ä–µ–Ω–¥–∞ (—Ç–µ–ø–µ—Ä—å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç tuple)
        trend, trend_percent = self._calculate_trend(filtered_items)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = {
            'avg_price': int(statistics.mean(prices)),
            'median_price': int(statistics.median(prices)),
            'min_price': int(min(prices)),
            'max_price': int(max(prices)),
            'sample_count': len(filtered_items),
            'trend': trend,
            'trend_percent': round(trend_percent, 1)
        }

        # –ö–µ—à–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        self._cache_stats(product_key, context)

        print(f"[Memory] üìä RAG context: {len(filtered_items)} items (filtered from {len(similar_items)}), avg={context['avg_price']}, trend={trend} ({trend_percent:+.1f}%)")
        return context

    def _calculate_trend(self, items: List[Dict]) -> tuple[str, float]:
        """
        –†–∞—Å—á–µ—Ç —Ç—Ä–µ–Ω–¥–∞ —Ü–µ–Ω (up/down/stable) + –ø—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
        Args:
            items: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤ (—Å added_at –∏ price)
        Returns:
            ("up"/"down"/"stable", –ø—Ä–æ—Ü–µ–Ω—Ç_–∏–∑–º–µ–Ω–µ–Ω–∏—è)
        """
        if len(items) < 3:
            return ("stable", 0.0)

        try:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
            sorted_items = sorted(items, key=lambda x: x.get('added_at', ''))

            # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç—Ä–µ—Ç—å
            third = len(sorted_items) // 3
            early = sorted_items[:third]
            late = sorted_items[-third:]

            early_prices = [i['price'] for i in early if i.get('price')]
            late_prices = [i['price'] for i in late if i.get('price')]

            if not early_prices or not late_prices:
                return ("stable", 0.0)

            avg_early = statistics.mean(early_prices)
            avg_late = statistics.mean(late_prices)

            # –ü—Ä–æ—Ü–µ–Ω—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è
            percent_change = ((avg_late - avg_early) / avg_early) * 100

            # –ü–æ—Ä–æ–≥ –∏–∑–º–µ–Ω–µ–Ω–∏—è: 10%
            if avg_late > avg_early * 1.1:
                return ("up", percent_change)
            elif avg_late < avg_early * 0.9:
                return ("down", percent_change)
            else:
                return ("stable", percent_change)
        except Exception as e:
            print(f"[Memory] Trend calculation error: {e}")
            return ("stable", 0.0)

    # ==================== –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ ====================

    def _generate_product_key(self, title: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        keywords = self._extract_keywords(title)
        return ' '.join(keywords[:3])  # –ü–µ—Ä–≤—ã–µ 3 –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞

    def _get_cached_stats(self, product_key: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –∫–µ—à–∞ (–µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞—Ä–µ–ª–∞)"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            c = conn.cursor()

            c.execute("""
                SELECT * FROM statistics
                WHERE product_key = ?
                AND last_updated >= datetime('now', '-1 hour')
            """, (product_key,))

            row = c.fetchone()
            conn.close()

            if row:
                return dict(row)
            return None

        except Exception as e:
            print(f"[Memory] Cache read error: {e}")
            return None

    def _cache_stats(self, product_key: str, context: Dict):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–µ—à"""
        try:
            conn = sqlite3.connect(self.db_path)
            c = conn.cursor()
            now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            c.execute("""
                INSERT OR REPLACE INTO statistics
                (product_key, avg_price, median_price, min_price, max_price,
                 sample_count, trend, trend_percent, last_updated)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                product_key,
                context['avg_price'],
                context['median_price'],
                context['min_price'],
                context['max_price'],
                context['sample_count'],
                context['trend'],
                context.get('trend_percent', 0.0),
                now_str
            ))

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é —Ç—Ä–µ–Ω–¥–æ–≤
            date_str = datetime.now().strftime("%Y-%m-%d")
            c.execute("""
                INSERT OR REPLACE INTO trend_history
                (product_key, date, avg_price, sample_count)
                VALUES (?, ?, ?, ?)
            """, (product_key, date_str, context['avg_price'], context['sample_count']))

            conn.commit()
            conn.close()
        except Exception as e:
            print(f"[Memory] Cache write error: {e}")

    def _invalidate_stats_cache(self, title: str):
        """–ò–Ω–≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–µ—à–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞"""
        try:
            product_key = self._generate_product_key(title)
            conn = sqlite3.connect(self.db_path)
            c = conn.cursor()
            c.execute("DELETE FROM statistics WHERE product_key = ?", (product_key,))
            conn.commit()
            conn.close()
        except Exception:
            pass
    
    def rebuild_statistics_cache(self) -> int:
        """
        –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –≤—Å–µ –∞–≥—Ä–µ–≥–∞—Ç—ã —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            c = conn.cursor()
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ product_key –∏–∑ items
            c.execute("SELECT DISTINCT title FROM items")
            titles = [row['title'] for row in c.fetchall()]
            conn.close()
            
            print(f"[Memory] üîç Found {len(titles)} unique titles")  # DEBUG
            
            if not titles:
                print("[Memory] ‚ö†Ô∏è No titles found, database might be empty")
                return 0
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º product_key –∏ —Å–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ
            product_keys = set()
            for title in titles:
                pk = self._generate_product_key(title)
                if pk:
                    product_keys.add(pk)
            
            print(f"[Memory] üîÑ Rebuilding stats for {len(product_keys)} categories...")
            
            rebuilt = 0
            for pk in product_keys:
                # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                keywords = pk.split()
                if not keywords:
                    continue
                
                # –°—Ç—Ä–æ–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π title –¥–ª—è –ø–æ–∏—Å–∫–∞
                temp_title = " ".join(keywords)
                similar = self.find_similar_items(temp_title, limit=100)
                
                if len(similar) < 2:
                    print(f"[Memory] ‚ö†Ô∏è Category '{pk}': too few items ({len(similar)})")
                    continue
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π)
                cutoff_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
                filtered = [item for item in similar if item.get('added_at', '') >= cutoff_date]
                
                if len(filtered) < 2:
                    print(f"[Memory] ‚ö†Ô∏è Category '{pk}': too few recent items ({len(filtered)})")
                    continue
                
                # –°—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                prices = [item['price'] for item in filtered if item.get('price')]
                if not prices:
                    continue
                
                trend, trend_percent = self._calculate_trend(filtered)
                
                context = {
                    'avg_price': int(statistics.mean(prices)),
                    'median_price': int(statistics.median(prices)),
                    'min_price': int(min(prices)),
                    'max_price': int(max(prices)),
                    'sample_count': len(filtered),
                    'trend': trend,
                    'trend_percent': round(trend_percent, 1)
                }
                
                self._cache_stats(pk, context)
                rebuilt += 1
                print(f"[Memory] ‚úÖ Category '{pk}': avg={context['avg_price']}, trend={trend}")
            
            print(f"[Memory] ‚úÖ Rebuild complete: {rebuilt}/{len(product_keys)} categories")
            return rebuilt
            
        except Exception as e:
            print(f"[Memory] ‚ùå Rebuild error: {e}")
            import traceback
            traceback.print_exc()
            return 0

    def get_all_statistics(self, limit: int = 100) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ–ª—è–º–∏: product_key, avg_price, trend, trend_percent, sample_count, last_updated
        """
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            c = conn.cursor()

            c.execute("""
                SELECT * FROM statistics
                ORDER BY last_updated DESC
                LIMIT ?
            """, (limit,))

            rows = [dict(row) for row in c.fetchall()]
            conn.close()
            return rows

        except Exception as e:
            print(f"[Memory] Get statistics error: {e}")
            return []

    def get_stats_for_product_key(self, product_key: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∞–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É product_key –∏–∑ —Ç–∞–±–ª–∏—Ü—ã statistics"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            c = conn.cursor()
            c.execute("""
                SELECT * FROM statistics
                WHERE product_key = ?
            """, (product_key,))
            row = c.fetchone()
            conn.close()
            return dict(row) if row else None
        except Exception as e:
            print(f"[Memory] Get stats by key error: {e}")
            return None

    def get_stats_for_title(self, title: str) -> Optional[Dict]:
        """
        RAG ENGINE: –ò—â–µ—Ç –ø–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä—ã–Ω–∫–∞.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç IQR –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –≤—ã–±—Ä–æ—Å–æ–≤ (—á–µ—Ö–ª–æ–≤, –∫–æ—Ä–æ–±–æ–∫, –æ—à–∏–±–æ–∫).
        """
        if not title:
            return None
            
        # 1. –í—ã–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ (—Å–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ –∏–∑ –∑–Ω–∞—á–∏–º—ã—Ö)
        ignore = {'–ø—Ä–æ–¥–∞–º', '–∫—É–ø–ª—é', '–Ω–æ–≤—ã–π', '—Å–æ—Å—Ç–æ—è–Ω–∏–µ', '—Ç–æ—Ä–≥', 'original', '–æ—Ä–∏–≥–∏–Ω–∞–ª', '–∫–æ–º–ø–ª–µ–∫—Ç', '–ø–æ–ª–Ω—ã–π', '–∏–¥–µ–∞–ª—å–Ω–æ–µ', '–æ—Ç–ª–∏—á–Ω–æ–µ'}
        clean_words = [w for w in title.lower().split() if len(w) > 3 and w not in ignore]
        if not clean_words:
            return None
            
        keyword = max(clean_words, key=len) # –°–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–ª–æ–≤–æ - –ª—É—á—à–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç (–Ω–∞–ø—Ä. 'macbook', 'playstation')

        # 2. –ò—â–µ–º —Ü–µ–Ω—ã –≤ –±–∞–∑–µ
        with self._get_conn() as conn:
            cursor = conn.cursor()
            # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É
            cursor.execute("SELECT price FROM items WHERE title LIKE ? AND price > 100", (f"%{keyword}%",))
            rows = cursor.fetchall()
            
        raw_prices = [r[0] for r in rows if r[0] is not None]
        
        if len(raw_prices) < 3: # –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            return None

        # 3. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤—ã–±—Ä–æ—Å–æ–≤ (IQR –º–µ—Ç–æ–¥)
        sorted_prices = sorted(raw_prices)
        q1 = sorted_prices[len(sorted_prices)//4]
        q3 = sorted_prices[3*len(sorted_prices)//4]
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        
        filtered_prices = [p for p in sorted_prices if lower_bound <= p <= upper_bound]
        
        if not filtered_prices: # –ï—Å–ª–∏ –≤—Å–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–æ—Å—å (—Å—Ç—Ä–∞–Ω–Ω–æ), –±–µ—Ä–µ–º —Å—ã—Ä—ã–µ
            filtered_prices = sorted_prices

        # 4. –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        try:
            avg_price = int(statistics.mean(filtered_prices))
            median_price = int(statistics.median(filtered_prices))
            min_price = filtered_prices[0]
            max_price = filtered_prices[-1]
            
            # –û—Ü–µ–Ω–∫–∞ —Ç—Ä–µ–Ω–¥–∞ (–≥—Ä—É–±–∞—è: —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 3 –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å –æ–±—â–µ–π —Å—Ä–µ–¥–Ω–µ–π)
            # –¢—É—Ç –º—ã –Ω–µ –∑–Ω–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ raw_prices, –Ω–æ –¥–æ–ø—É—Å—Ç–∏–º. 
            # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –≤–µ—Ä–Ω–µ–º "stable"
            trend = "stable" 
            
            return {
                "keyword": keyword,
                "sample_count": len(raw_prices), # –û–±—â–µ–µ –∫–æ–ª-–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö
                "clean_count": len(filtered_prices), # –ö–æ–ª-–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞
                "avg_price": avg_price,
                "median_price": median_price,
                "min_price": min_price,
                "max_price": max_price,
                "trend": trend
            }
        except Exception as e:
            print(f"RAG Error calculation: {e}")
            return None

    def get_rag_context_for_product_key(self, product_key: str) -> Optional[Dict]:
        stats = self.get_stats_for_product_key(product_key)
        if not stats:
            return None
        return {
            "product_key": product_key,
            "avg_price": stats.get("avg_price"),
            "median_price": stats.get("median_price"),
            "min_price": stats.get("min_price"),
            "max_price": stats.get("max_price"),
            "sample_count": stats.get("sample_count"),
            "trend": stats.get("trend"),
            "trend_percent": stats.get("trend_percent", 0.0),
        }

    # ==================== –£—Ç–∏–ª–∏—Ç—ã ====================

    def get_rag_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å RAG-—Å–∏—Å—Ç–µ–º—ã –¥–ª—è UI
        Returns:
            {
                'total_items': int,
                'total_categories': int,
                'last_rebuild': str (timestamp),
                'status': 'ok' | 'outdated' | 'empty'
            }
        """
        try:
            conn = sqlite3.connect(self.db_path)
            c = conn.cursor()
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
            c.execute("SELECT COUNT(*) FROM items")
            total_items = c.fetchone()[0]
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            c.execute("SELECT COUNT(*) FROM statistics")
            total_categories = c.fetchone()[0]
            
            # –ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
            c.execute("SELECT MAX(last_updated) FROM statistics")
            last_updated = c.fetchone()[0]
            
            conn.close()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
            if total_items == 0:
                status = 'empty'
            elif last_updated:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É—Å—Ç–∞—Ä–µ–ª–æ –ª–∏ (–±–æ–ª–µ–µ 1 —á–∞—Å–∞)
                last_dt = datetime.strptime(last_updated, "%Y-%m-%d %H:%M:%S")
                if datetime.now() - last_dt > timedelta(hours=1):
                    status = 'outdated'
                else:
                    status = 'ok'
            else:
                status = 'outdated'
            
            return {
                'total_items': total_items,
                'total_categories': total_categories,
                'last_rebuild': last_updated or 'Never',
                'status': status
            }
            
        except Exception as e:
            print(f"[Memory] Get RAG status error: {e}")
            return {
                'total_items': 0,
                'total_categories': 0,
                'last_rebuild': 'Error',
                'status': 'empty'
            }

    def get_all_items(self, limit=100) -> List[Dict]:
        with self._get_conn() as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM items ORDER BY id DESC LIMIT ?", (limit,))
            return [dict(row) for row in cursor.fetchall()]

        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            c = conn.cursor()
            c.execute("SELECT * FROM items ORDER BY added_at DESC LIMIT ?", (limit,))
            rows = [dict(row) for row in c.fetchall()]
            conn.close()
            return rows
        except Exception as e:
            print(f"[Memory] Get Error: {e}")
            return []

    def delete_item(self, avito_id: str):
       with self._get_conn() as conn:
            cursor = conn.cursor()
            cursor.execute("DELETE FROM items WHERE avito_id = ?", (str(avito_id),))
            conn.commit()
            return cursor.rowcount > 0

    def clear_all(self):
        with self._get_conn() as conn:
            conn.execute("DELETE FROM items")
            conn.commit()

    def get_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–∞–º—è—Ç–∏"""
        if not hasattr(self, 'db_path'):
            return {"total": 0, "great": 0}

        try:
            conn = sqlite3.connect(self.db_path)
            c = conn.cursor()
            c.execute("SELECT COUNT(*) FROM items")
            total = c.fetchone()[0]
            c.execute("SELECT COUNT(*) FROM items WHERE verdict='GREAT_DEAL'")
            great = c.fetchone()[0]
            conn.close()

            return {"total": total, "great": great}
        except:
            return {"total": 0, "great": 0}

    def get_context_as_text(self, limit=50) -> str:
        """–¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–ª—è —á–∞—Ç–∞"""
        items = self.get_all_items(limit)
        if not items:
            return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞."

        items.sort(key=lambda x: x['price'] if x['price'] is not None else float('inf'))

        text_parts = [f"–í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –≤—Å–µ–≥–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤. –°–ø–∏—Å–æ–∫ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ —Ü–µ–Ω–µ):"]
        for idx, i in enumerate(items, 1):
            verdict = i['verdict'] or "N/A"
            price = i['price'] or 0
            title = i['title'] or "No Title"
            title = " ".join(title.split())
            city = i['city'] or "Unknown"
            line = f"{idx}. [{verdict}] {price} —Ä—É–±. | {title} | {city}"
            text_parts.append(line)

        return "\n".join(text_parts)
    
    def get_category_summary_text(self, top_n: int = 10) -> str:
        """
        –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ —Ç–æ–ø-N –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏–∑ —Ç–∞–±–ª–∏—Ü—ã statistics
        –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —á–∞—Ç-–ø—Ä–æ–º–ø—Ç–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏.
        """
        try:
            stats = self.get_all_statistics(limit=top_n)
        except Exception:
            return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏."

        if not stats:
            return "–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø—É—Å—Ç–∞."

        lines = ["–ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ —Ä—ã–Ω–∫—É (—Ç–æ–≤–∞—Ä: —Å—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ (–º–µ–¥–∏–∞–Ω–∞, –∫–æ–ª-–≤–æ) —Ç—Ä–µ–Ω–¥):"]
        for st in stats:
            name = st.get('product_key') or "N/A"
            avg = st.get('avg_price') or 0
            med = st.get('median_price') or 0
            count = st.get('sample_count') or 0
            trend = st.get('trend') or 'stable'
            tp = st.get('trend_percent') or 0.0

            avg_fmt = f"{avg//1000}–∫" if avg > 1000 else str(avg)
            med_fmt = f"{med//1000}–∫" if med > 1000 else str(med)
            trend_icon = "‚ÜóÔ∏è" if trend == 'up' else "‚ÜòÔ∏è" if trend == 'down' else "‚û°Ô∏è"
            
            line = f"- {name}: {avg_fmt} (med:{med_fmt}, n={count}) {trend_icon}{tp:+.0f}%"
            lines.append(line)
        
        return "\n".join(lines)

    def cleanup_old_data(self, days_to_keep=90):
        """–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π —Å—Ç–∞—Ä—à–µ N –¥–Ω–µ–π"""
        if not hasattr(self, 'db_path'):
            return

        try:
            cutoff = (datetime.now() - timedelta(days=days_to_keep)).strftime("%Y-%m-%d")
            conn = sqlite3.connect(self.db_path)
            c = conn.cursor()

            c.execute("DELETE FROM items WHERE added_at < ?", (cutoff,))
            deleted = c.rowcount
            conn.commit()
            conn.close()

            print(f"[Memory] üóëÔ∏è Cleanup: {deleted} items older than {days_to_keep} days")
        except Exception as e:
            print(f"[Memory] Cleanup error: {e}")